{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The20thDuck/Neuro-140-Project/blob/main/main_experiments/CIFAR_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWSTlMOZEhNP"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from matplotlib.colors import Colormap\n",
        "!pip install wandb -qqq\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFEYcUZbEnpa",
        "outputId": "78ae1096-4a74-41a2-ff68-7e3d620213ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# train_data = torchvision.datasets.FashionMNIST(\"data\", train=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]), download=True)\n",
        "# train_loader = t.utils.data.DataLoader(train_data, batch_size = 128, shuffle=True, num_workers=2)\n",
        "batch_size = 128\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "getloader = lambda x: t.utils.data.DataLoader(x, batch_size = batch_size, shuffle=True, num_workers=2)\n",
        "train_loader = getloader(train_data)\n",
        "test_loader = getloader(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "irR9HG8qFoZz",
        "outputId": "6889d555-af38-42f5-8691-9ae137ddc20b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc9ab263450>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(transforms.ToPILImage()(transforms.Normalize((-1, -1, -1), (2, 2, 2))(train_data[0][0].squeeze())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL6meaQAkXJV",
        "outputId": "b9623a05-60a9-4df1-c934-cd645f83af14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n",
        "!pip install pytorch-ignite pytorch-fid -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L72Wx4DYFrBX"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "ngc = 64\n",
        "latent_size = 100\n",
        "num_classes = 10\n",
        "emb_size = 128\n",
        "in_channels = 3\n",
        "wand_b = True\n",
        "img_size = 32\n",
        "\n",
        "class Generator(t.nn.Module):\n",
        "  def __init__(self, \n",
        "               latent_size=latent_size, \n",
        "               emb_size = emb_size, \n",
        "               nhead=8,\n",
        "               L1 = 4,\n",
        "               L2 = 4,\n",
        "               L3 = 2,\n",
        "               img_size = img_size,\n",
        "               in_channels=in_channels):\n",
        "    super().__init__()\n",
        "    self.emb_size = emb_size\n",
        "    self.img_size = img_size\n",
        "    # self.latent_size = latent_size\n",
        "    self.linear1 = t.nn.Linear(latent_size, emb_size*(img_size//4)**2)\n",
        "    self.pos_emb1 = t.nn.Parameter(t.randn(1, (img_size//4)**2, emb_size))\n",
        "    self.block1 = t.nn.Sequential(\n",
        "        *[t.nn.TransformerEncoderLayer(\n",
        "        emb_size,\n",
        "        nhead=nhead, \n",
        "        dim_feedforward=emb_size*4, \n",
        "        activation=\"gelu\",\n",
        "        norm_first=True,\n",
        "        batch_first=True, \n",
        "        dropout=0., \n",
        "        layer_norm_eps=1e-12\n",
        "      ) for _ in range(L1)]\n",
        "    )\n",
        "    self.pixel1 = t.nn.PixelShuffle(2)\n",
        "    self.block2 = t.nn.Sequential(\n",
        "        *[t.nn.TransformerEncoderLayer(\n",
        "        emb_size//4,\n",
        "        nhead=nhead, \n",
        "        dim_feedforward=emb_size, \n",
        "        activation=\"gelu\",\n",
        "        norm_first=True,\n",
        "        batch_first=True, \n",
        "        dropout=0., \n",
        "        layer_norm_eps=1e-12\n",
        "      ) for _ in range(L2)]\n",
        "    )\n",
        "    self.pixel2 = t.nn.PixelShuffle(2)\n",
        "    self.block3 = t.nn.Sequential(\n",
        "        *[t.nn.TransformerEncoderLayer(\n",
        "        emb_size//16,\n",
        "        nhead=nhead, \n",
        "        dim_feedforward=emb_size, \n",
        "        activation=\"gelu\",\n",
        "        norm_first=True,\n",
        "        batch_first=True, \n",
        "        dropout=0., \n",
        "        layer_norm_eps=1e-12\n",
        "      ) for _ in range(L3)]\n",
        "    )\n",
        "    self.project = t.nn.Linear(emb_size//16, in_channels)\n",
        "    self.tanh = t.nn.Tanh()\n",
        "\n",
        "  def forward(self, z):\n",
        "    b = z.shape[0]\n",
        "    emb = self.linear1(z).view((b, (self.img_size//4)**2, self.emb_size))\n",
        "    emb = self.block1(emb + self.pos_emb1)\n",
        "    emb_to_pixel = \"b (h w) c -> b c h w\"\n",
        "    pixel_to_emb = \"b c h w -> b (h w) c\"\n",
        "\n",
        "    pixels = einops.rearrange(emb, emb_to_pixel, h = self.img_size//4)\n",
        "    pixels = self.pixel1(pixels)\n",
        "    emb = einops.rearrange(pixels, pixel_to_emb, h = self.img_size//2)\n",
        "    emb = self.block2(emb)\n",
        "    pixels = einops.rearrange(emb, emb_to_pixel, h = self.img_size//2)\n",
        "    pixels = self.pixel2(pixels)\n",
        "    emb = einops.rearrange(pixels, pixel_to_emb, h = self.img_size)\n",
        "    emb = self.block3(emb)\n",
        "    emb = self.project(emb)\n",
        "    pixels = einops.rearrange(emb, emb_to_pixel, h = self.img_size)\n",
        "    return self.tanh(pixels)\n",
        "\n",
        "class Generator_Conv(t.nn.Module):\n",
        "  def __init__(self, latent_size=latent_size, num_classes = num_classes,  in_channels = in_channels):\n",
        "    super().__init__()\n",
        "    self.layers = t.nn.Sequential(\n",
        "        t.nn.ConvTranspose2d(latent_size, ngc*4, 4, 1, 0),\n",
        "        t.nn.BatchNorm2d(ngc*4),\n",
        "        t.nn.ReLU(),\n",
        "        t.nn.ConvTranspose2d(ngc*4, ngc*2, 4, 2, 1),\n",
        "        t.nn.BatchNorm2d(ngc*2),\n",
        "        t.nn.ReLU(),\n",
        "        t.nn.ConvTranspose2d(ngc*2, ngc*1, 4, 2, 1),\n",
        "        t.nn.BatchNorm2d(ngc),\n",
        "        t.nn.ReLU(),\n",
        "        t.nn.ConvTranspose2d(ngc*1, in_channels, 4, 2, 1),\n",
        "        t.nn.Tanh()\n",
        "    )\n",
        "  def forward(self, z):\n",
        "    return self.layers(z.unsqueeze(-1).unsqueeze(-1))\n",
        "\n",
        "class PatchEmbedding(t.nn.Module):\n",
        "  def __init__(self, in_channels, patch_size, emb_size, img_size, cls = True):\n",
        "    super().__init__()\n",
        "    self.cls = cls\n",
        "    self.n = (img_size//patch_size)**2\n",
        "    self.emb_size = emb_size\n",
        "    if cls:\n",
        "      self.cls_token = t.nn.Parameter(t.randn(1, 1, emb_size)) # b, n, emb_size. Add to the list of module params\n",
        "      self.position_embeddings = t.nn.Parameter(t.randn(1, self.n + 1, emb_size)) # +1 for cls\n",
        "    else:\n",
        "      self.position_embeddings = t.nn.Parameter(t.randn(1, self.n, emb_size))\n",
        "\n",
        "    self.projection = t.nn.Conv2d(in_channels, emb_size, patch_size, patch_size, 0)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    token_embeddings = einops.rearrange(self.projection(inputs), 'b c h w -> b (h w) c')\n",
        "    b = inputs.shape[0]\n",
        "    if self.cls:\n",
        "      cls_embeddings = self.cls_token.repeat((b, 1, 1))\n",
        "      # print(cls_embeddings.shape, token_embeddings.shape, self.position_embeddings.shape)\n",
        "      return t.cat((cls_embeddings, token_embeddings), dim = 1) + self.position_embeddings\n",
        "    else:\n",
        "      return token_embeddings + self.position_embeddings\n",
        "\n",
        "class ClassificationHead(t.nn.Module):\n",
        "  def __init__(self, num_classes, emb_size):\n",
        "    super().__init__()\n",
        "    self.ln = t.nn.LayerNorm((emb_size,), eps = 1e-12)\n",
        "    self.layer = t.nn.Linear(emb_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer(self.ln(x)[:,0,:])\n",
        "\n",
        "\n",
        "class Discriminator(t.nn.Module):\n",
        "  def __init__(self, in_channels: int = in_channels, patch_size: int = 2, emb_size: int = emb_size, nhead=8, img_size=img_size, num_classes=1, L1 = 3, L2 = 3, from_hugging = False):\n",
        "    super().__init__()\n",
        "    self.img_size = img_size\n",
        "    self.patch_emb1 = PatchEmbedding(in_channels, patch_size, emb_size, img_size, cls=False)\n",
        "    self.patch_emb2 = PatchEmbedding(in_channels, patch_size*2, emb_size, img_size, cls=False)\n",
        "    self.cls_token = t.nn.Parameter(t.randn(1, 1, emb_size*2))\n",
        "    # self.from_hugging = from_hugging\n",
        "    # if from_hugging:\n",
        "    #   config = ViTConfig(hidden_size=emb_size, num_hidden_layers = L, num_attention_heads = nhead, intermediate_size=emb_size*4, patch_size=patch_size, image_size=imgsize, encoder_stride=patch_size)\n",
        "    #   self.encoder = ViTForImageClassification(config).vit.encoder\n",
        "    # else:\n",
        "    self.block1 = t.nn.Sequential(*[\n",
        "      t.nn.TransformerEncoderLayer(\n",
        "        emb_size,\n",
        "        nhead=nhead, \n",
        "        dim_feedforward=emb_size*4, \n",
        "        activation=\"gelu\",\n",
        "        norm_first=True,\n",
        "        batch_first=True, \n",
        "        dropout=0., \n",
        "        layer_norm_eps=1e-12\n",
        "      ) for _ in range(L1)])\n",
        "    self.avgpool = t.nn.AvgPool2d(2)\n",
        "    self.block2 = t.nn.Sequential(*[\n",
        "      t.nn.TransformerEncoderLayer(\n",
        "        emb_size*2,\n",
        "        nhead=nhead, \n",
        "        dim_feedforward=emb_size*4, \n",
        "        activation=\"gelu\",\n",
        "        norm_first=True,\n",
        "        batch_first=True, \n",
        "        dropout=0., \n",
        "        layer_norm_eps=1e-12\n",
        "      ) for _ in range(L2)])\n",
        "    self.classifier = ClassificationHead(num_classes, emb_size=emb_size*2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    emb1 = self.patch_emb1(x)\n",
        "    stage1 = self.block1(emb1)\n",
        "    emb_to_pixel = \"b (h w) c -> b c h w\"\n",
        "    pixel_to_emb = \"b c h w -> b (h w) c\"\n",
        "    stage1 = einops.rearrange(stage1, emb_to_pixel, h = self.img_size//2)\n",
        "    stage1 = self.avgpool(stage1)\n",
        "    stage1 = einops.rearrange(stage1, pixel_to_emb, h = self.img_size//4)\n",
        "    emb2 = self.patch_emb2(x)\n",
        "    emb2 = t.cat((emb2, stage1), dim = -1)\n",
        "    b = x.shape[0]\n",
        "    cls_embeddings = self.cls_token.repeat((b, 1, 1))\n",
        "    emb2 = t.cat((cls_embeddings, emb2), dim = 1)\n",
        "    emb2 = self.block2(emb2)\n",
        "    return t.sigmoid(self.classifier(emb2)).flatten()\n",
        "    \n",
        "\n",
        "class Discriminator_Conv(t.nn.Module):\n",
        "  def __init__(self, num_classes=num_classes, in_channels = in_channels):\n",
        "    super().__init__()\n",
        "    self.layers = t.nn.Sequential(\n",
        "        t.nn.Conv2d(in_channels, ngc, 4, 2, 1),\n",
        "        t.nn.BatchNorm2d(ngc*1),\n",
        "        t.nn.LeakyReLU(0.2),\n",
        "        t.nn.Conv2d(ngc*1, ngc*2, 4, 2, 1),\n",
        "        t.nn.BatchNorm2d(ngc*2),\n",
        "        t.nn.LeakyReLU(0.2),\n",
        "        t.nn.Conv2d(ngc*2, ngc*4, 4, 2, 1),\n",
        "        t.nn.BatchNorm2d(ngc*4),\n",
        "        t.nn.LeakyReLU(0.2),\n",
        "        t.nn.Conv2d(ngc*4, 1, 4, 1, 0),\n",
        "        t.nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.layers(x).flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BThcy-7muTqa",
        "outputId": "19f687a5-eb52-4b67-acf8-3090aa918c48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2cJCyxtI37g"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# arch = \"Transformer\"\n",
        "\n",
        "# if wand_b:\n",
        "#   wandb.init(\n",
        "#       # Set the project where this run will be logged\n",
        "#       project=\"Neuro-140\", \n",
        "#       # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
        "#       name=f\"transformer_gen_{run}\", \n",
        "#       # Track hyperparameters and run metadata\n",
        "#       config={\n",
        "#       \"learning_rate\": lr,\n",
        "#       \"emb_size\": emb_size,\n",
        "#       \"architecture\": arch\n",
        "#       })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU96ucC_NLaE"
      },
      "outputs": [],
      "source": [
        "from pytorch_fid.inception import InceptionV3\n",
        "\n",
        "device = \"cuda\"\n",
        "dims = 2048\n",
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
        "model = InceptionV3([block_idx]).to(device)\n",
        "\n",
        "class WrapperInceptionV3(t.nn.Module):\n",
        "    \n",
        "    def __init__(self, fid_incv3):\n",
        "        super().__init__()\n",
        "        self.fid_incv3 = fid_incv3\n",
        "    \n",
        "    @t.no_grad()\n",
        "    def forward(self, x):\n",
        "        y = self.fid_incv3(x)\n",
        "        y = y[0]\n",
        "        y = y[:, :, 0, 0]\n",
        "        return y\n",
        "\n",
        "wrapper_model = WrapperInceptionV3(model)\n",
        "wrapper_model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjyKp-ovN6Ra"
      },
      "outputs": [],
      "source": [
        "from ignite.metrics import FID\n",
        "from ignite.engine import Engine\n",
        "import ignite.distributed as idist\n",
        "def process_function(engine, batch):\n",
        "  return batch\n",
        "\n",
        "from torchvision import transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.CenterCrop(299),\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "engine = Engine(process_function)\n",
        "metric = FID(num_features=dims, feature_extractor=wrapper_model, device=idist.device())\n",
        "metric.attach(engine, \"fid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjmnGIIzOS9J"
      },
      "outputs": [],
      "source": [
        "def calc_fid(metric, gen, latent_size):\n",
        "  metric.reset()\n",
        "  gen.eval()\n",
        "  with t.no_grad():\n",
        "    for i, (x, y) in enumerate(tqdm(train_loader)):\n",
        "      b = x.shape[0]\n",
        "      z = t.randn(b, latent_size).cuda()\n",
        "      gz = gen(z)\n",
        "      if in_channels == 1:\n",
        "        gz = t.tile(gz, (1, 3, 1, 1))\n",
        "        x = t.tile(x, (1, 3, 1, 1))\n",
        "      gz_resize = preprocess(gz)\n",
        "      x_resize = preprocess(x)\n",
        "      metric.update([x_resize, gz_resize])\n",
        "      if i == 100:\n",
        "        break\n",
        "  gen.train()\n",
        "  return (metric.compute())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUKaydBw8F8f"
      },
      "outputs": [],
      "source": [
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGrehfZstkLS"
      },
      "outputs": [],
      "source": [
        "# Initialize Sweep \n",
        "sweep_config = {\n",
        "  \"method\": \"grid\",\n",
        "  \"parameters\": {\n",
        "      \"lr\": {\n",
        "          \"values\": [1e-4, 3e-5, 1e-5]\n",
        "      },\n",
        "      \"gen_emb_size\": {\n",
        "          \"value\": 256\n",
        "      },\n",
        "      \"disc_emb_size\": {\n",
        "          \"value\": 128\n",
        "      },\n",
        "      \"latent_size\": {\n",
        "          \"value\": 100\n",
        "      },\n",
        "      \"gen\": {\n",
        "          \"values\": [\"transformer\", \"conv\"]\n",
        "      },\n",
        "      \"disc\": {\n",
        "          \"value\": \"transformer\"\n",
        "      },\n",
        "      \"epochs\": {\n",
        "          \"value\": 50\n",
        "      }\n",
        "  }\n",
        "}\n",
        "# sweep_id = wandb.sweep(sweep_config, project=\"CIFAR-transformer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEc-3RT8aZqm"
      },
      "outputs": [],
      "source": [
        "def train(config, wand_b = True):\n",
        "    lr = config.lr\n",
        "    beta1 = 0.5\n",
        "    if config.gen == \"conv\":\n",
        "      gen = Generator_Conv(latent_size=config.latent_size).cuda()\n",
        "    else:\n",
        "      gen = Generator(latent_size=config.latent_size, emb_size=config.gen_emb_size).cuda()\n",
        "    if config.disc == \"conv\":\n",
        "      disc = Discriminator_Conv().cuda()\n",
        "    else:\n",
        "      disc = Discriminator(emb_size=config.disc_emb_size).cuda()\n",
        "    optim_g = t.optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optim_d = t.optim.Adam(disc.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    criterion = t.nn.BCELoss()\n",
        "\n",
        "    iter = 0\n",
        "    epoch = 0\n",
        "    fixed_z = t.randn(10, config.latent_size).cuda()\n",
        "\n",
        "    # begin training\n",
        "    num_epochs = config.epochs\n",
        "    real_label = 1.\n",
        "    fake_label = 0.\n",
        "\n",
        "\n",
        "    d_losses = []\n",
        "    g_losses = []\n",
        "    dxs = []\n",
        "    dgzs = []\n",
        "    for e in range(num_epochs):\n",
        "      epoch += 1\n",
        "      for step, (x, _) in enumerate(tqdm(train_loader)):\n",
        "        iter += 1\n",
        "        # lab = t.nn.functional.one_hot(y.cuda(), num_classes = num_classes).float()\n",
        "        # update G\n",
        "        gen.zero_grad()\n",
        "        disc.zero_grad()\n",
        "        b = x.shape[0]\n",
        "        with t.no_grad():\n",
        "          z = t.randn(b, config.latent_size).cuda()\n",
        "        gz = gen(z)\n",
        "        dgz = disc(gz)\n",
        "        \n",
        "        g_loss = criterion(dgz, t.full((b,), real_label).cuda())\n",
        "        g_losses.append(g_loss.item())\n",
        "        g_loss.backward()\n",
        "        optim_g.step()\n",
        "        # update D\n",
        "        disc.zero_grad()\n",
        "        dx = disc(x.cuda())\n",
        "        dgz = disc(gz.detach())\n",
        "        dxs.append(dx.detach())\n",
        "        dgzs.append(dgz.detach())\n",
        "\n",
        "        d_loss = criterion(dgz, t.full((b,), fake_label).cuda()) + criterion(dx, t.full((b,), real_label).cuda())\n",
        "        d_losses.append(d_loss.item())\n",
        "        d_loss.backward()\n",
        "        optim_d.step()\n",
        "\n",
        "        if iter % 100 == 0:\n",
        "          L_g = t.tensor(g_losses[-100:]).mean()\n",
        "          L_d = t.tensor(d_losses[-100:]).mean()\n",
        "          dx_mean = t.cat(dxs[-100:]).mean().item()\n",
        "          dgz_mean = t.cat(dgzs[-100:]).mean().item()\n",
        "          d_losses = []\n",
        "          g_losses = []\n",
        "          dxs = []\n",
        "          dgzs = []\n",
        "          if wand_b:\n",
        "            wandb.log({\"G-Loss\": L_g, \n",
        "                      \"D-Loss\": L_d,\n",
        "                      \"dx\": dx_mean,\n",
        "                      \"dgz\": dgz_mean,\n",
        "                      \"iter\": iter\n",
        "                      })\n",
        "\n",
        "      with t.no_grad():\n",
        "        ims = gen(fixed_z).cpu()\n",
        "        \n",
        "      fid = calc_fid(metric, gen, latent_size = config.latent_size)\n",
        "      print(f\"FID: {fid}\")\n",
        "      if wand_b:\n",
        "        norm_images = transforms.Normalize((-1, -1, -1), (2, 2, 2))(ims)\n",
        "        log_dict = {f\"FID\": fid,\n",
        "                  #  f\"{arch}/G-Loss\": t.tensor(g_losses).mean(), \n",
        "                  #  f\"{arch}/D-Loss\": t.tensor(d_losses).mean(),\n",
        "                  # f\"Images\": [wandb.Image(im.numpy()*255) for im in ims],\n",
        "                  \"Images\": [wandb.Image(transforms.ToPILImage()(im)) for im in norm_images],\n",
        "                  \"epoch\": epoch\n",
        "                  }\n",
        "        if epoch == num_epochs:\n",
        "          log_dict.update({\n",
        "              \"FID_Final\": fid\n",
        "          })\n",
        "        wandb.log(log_dict)\n",
        "\n",
        "def train_config(config = None):\n",
        "  with wandb.init(config=config):\n",
        "    config = wandb.config\n",
        "    train(config)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2bYjowa4C7x",
        "outputId": "92ca1641-1db7-461e-861d-da61cd6f7f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May  5 15:24:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    40W / 300W |   4893MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jz5fuzNSv78"
      },
      "outputs": [],
      "source": [
        "# class dotdict(dict):\n",
        "#     \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "#     __getattr__ = dict.get\n",
        "#     __setattr__ = dict.__setitem__\n",
        "#     __delattr__ = dict.__delitem__\n",
        "# train(config = dotdict({\"lr\": 1e-4, \"gen_emb_size\": 256, \"disc_emb_size\": 128, \"latent_size\": 100, \"gen\": \"transformer\", \"disc\": \"transformer\", \"epochs\": 50}), wand_b = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PPRW74B2I5vD",
        "outputId": "228ff3a8-7c91-45c0-b46c-ad5ab4e86097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nrb23vgo with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdisc: transformer\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdisc_emb_size: 192\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgen: conv\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgen_emb_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_152503-nrb23vgo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wsunadawong/CIFAR-transformer/runs/nrb23vgo\" target=\"_blank\">gentle-sweep-3</a></strong> to <a href=\"https://wandb.ai/wsunadawong/CIFAR-transformer\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/wsunadawong/CIFAR-transformer/sweeps/v66yl21b\" target=\"_blank\">https://wandb.ai/wsunadawong/CIFAR-transformer/sweeps/v66yl21b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:05,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 403.2853861436653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.14it/s]\n",
            " 26%|██▌       | 100/391 [00:43<02:06,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 441.2788465229978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:43<02:05,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 420.548186692905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:05,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 431.74692929225716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:43<02:05,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 420.1152291451159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:43<02:05,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 349.0678537706375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:35<00:00,  4.11it/s]\n",
            " 26%|██▌       | 100/391 [00:43<02:05,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 361.4931913180464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:04,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 321.8982645310373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:43<02:05,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 285.7509777277711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:04,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 261.3822115381628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:05,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 246.58681945438332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:05,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 245.5463076834334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:04,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 244.9238335557945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:43<02:05,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 256.8611031801115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.12it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:04,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 280.97740670296173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:04,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 244.4596366816936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:04,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 233.25239685280462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:05,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 236.82734743622322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:04,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 206.4639617376729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:04,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 200.44687435057307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.14it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:03,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 199.20931837372467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:03,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 195.00399850420126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.14it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:03,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 187.20012956831548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.13it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:03,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 192.0745829089151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.14it/s]\n",
            " 26%|██▌       | 100/391 [00:42<02:03,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID: 187.1557129597988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [01:34<00:00,  4.14it/s]\n",
            "  6%|▋         | 25/391 [00:10<02:33,  2.38it/s]"
          ]
        }
      ],
      "source": [
        "wandb.agent(\"v66yl21b\", train_config, project=\"CIFAR-transformer\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL0dY_gbXHJo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CIFAR_GAN2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}